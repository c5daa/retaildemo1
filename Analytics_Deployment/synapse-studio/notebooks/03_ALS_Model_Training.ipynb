{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. \n",
        "Licensed under the MIT license. \n",
        "## Model Training Script for Synapse-AI-Retail-Recommender  \n",
        "Model Author (Data Scientist): Xiaoyong Zhu  \n",
        "  \n",
        "This script is an adapted script of the full Model Training script that can be found in `4. ML Model Building`. This is a slimmed down version that only has the required operations for producing a model that the Model Deployment Process and the RecommendationRefresh notebook can consume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "from pyspark.sql.functions import unix_timestamp\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.ml.feature import RFormula\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.authentication import ServicePrincipalAuthentication\n",
        "from azureml.core.run import Run\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.model import Model\n",
        "import os\n",
        "import shutil\n",
        "from shutil import rmtree\n",
        "import json\n",
        "import pprint"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect To Azure Machine Learning Workspace Using Service Principal"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "subscription_id = ''\n",
        "workspace_name = ''\n",
        "tenant_id = ''\n",
        "service_principal_id = ''\n",
        "service_principal_password = ''\n",
        "\n",
        "# Service Principal Authentication\n",
        "sp = ServicePrincipalAuthentication(tenant_id = tenant_id, # tenantID\n",
        "                                    service_principal_id = service_principal_id, # clientId\n",
        "                                    service_principal_password = service_principal_password) # clientSecret\n",
        "\n",
        "# Connect to your Azure Machine Learning Workspace using the Service Principal\n",
        "ws = Workspace.get(name = workspace_name, \n",
        "                   auth = sp,\n",
        "                   subscription_id = subscription_id)\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Ingestion\n",
        "Read Spark table as a Spark dataframe"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "df = spark.read.table(\"retailaidb.cleaned_dataset\")\n",
        "spark.sparkContext.setCheckpointDir('checkpoint/')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Filter only for Electronics items\n",
        "\n",
        "df = df.withColumn('category_code_new', df['category_code'].substr(0, 11))\n",
        "df = df.filter(\"category_code_new = 'electronics'\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "top_category = df.groupBy('category_code_new').count().sort('count', ascending=False).limit(5) # only keep top 5 categories\n",
        "top_category = top_category.withColumnRenamed(\"category_code_new\",\"category_code_tmp\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "item_to_save = df.groupBy('product_id', \"category_code\").count().sort('count', ascending=False)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "item_to_save = item_to_save.join(top_category, top_category.category_code_tmp == item_to_save.category_code).limit(20)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "raw_df = df\n",
        "\n",
        "product_count = df.groupBy('product_id').count()\n",
        "product_count = product_count.filter(\"count >= 30000\").orderBy('count', ascending=False) # only counts when the product has 30000 views\n",
        "\n",
        "raw_df = raw_df.withColumnRenamed(\"product_id\",\"product_id_tmp\")\n",
        "raw_df = raw_df.join(product_count, raw_df.product_id_tmp == product_count.product_id)\n",
        "\n",
        "user_count = df.groupBy('user_id').count()\n",
        "user_count = user_count.filter(\"count >= 200\").orderBy('count', ascending=False) # only counts when the user has 200 clicks\n",
        "\n",
        "raw_df = raw_df.withColumnRenamed(\"user_id\",\"user_id_tmp\")\n",
        "raw_df = raw_df.join(user_count, raw_df.user_id_tmp == user_count.user_id)\n",
        "\n",
        "df = raw_df\n",
        "\n",
        "df = df.where(df.event_type == \"view\")\n",
        "df = df.drop(\"event_time\",\"category_code\",\"user_session\",\"price\",\"brand\",\"category_id\")\n",
        "df = df.groupBy([df.product_id, df.user_id]).count()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# save table for further use\n",
        "df.write.saveAsTable(\"retailaidb.cleaned_dataset_electronics\", mode=\"overwrite\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "df = df.withColumn(\"user_id\", df[\"user_id\"].cast(IntegerType()))\n",
        "df = df.withColumn(\"product_id\", df[\"product_id\"].cast(IntegerType()))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "#split the data into training and test datatset\n",
        "train,test=df.randomSplit([0.75,0.25])"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "os.path.join(os.getcwd())"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# define variables for experiment, model name, file path, seed value\n",
        "experiment_name = 'retail_ai_experiment'\n",
        "model_name = 'retailai_recommendation_model.pkl'\n",
        "model_path = os.path.join(os.path.join(os.getcwd()), model_name)\n",
        "random_seed_val = 12345\n",
        "\n",
        "# start a training run by defining an experiment\n",
        "experiment = Experiment(workspace = ws, name = experiment_name)\n",
        "run = experiment.start_logging()\n",
        "\n",
        "# create an ALS recommender\n",
        "maxIter = 40\n",
        "regParam = 0.20\n",
        "rank = 25\n",
        "rec = ALS(maxIter = maxIter,regParam = regParam, rank = rank, implicitPrefs = True, userCol = 'user_id', itemCol = 'product_id', \\\n",
        "          ratingCol = 'count', nonnegative = True, coldStartStrategy = 'drop')\n",
        "\n",
        "# fit the model on train set\n",
        "rec_model = rec.fit(train)\n",
        "# making predictions on test set \n",
        "predicted_ratings = rec_model.transform(test)\n",
        "\n",
        "# create Regressor evaluator object for measuring accuracy\n",
        "evaluator = RegressionEvaluator(metricName = 'rmse', predictionCol = 'prediction', labelCol = 'count')\n",
        "# apply the RE on predictions dataframe to calculate RMSE\n",
        "rmse = evaluator.evaluate(predicted_ratings)\n",
        "\n",
        "# log hyperparameters and evaluation metrics to Azure ML\n",
        "run.log('maxIter', maxIter)\n",
        "run.log('regParam', regParam)\n",
        "run.log('rank', rank)\n",
        "run.log('RMSE', rmse)\n",
        "run.log_list('columns', train.columns)\n",
        "\n",
        "# save model\n",
        "rec_model.write().overwrite().save(\"retailai_recommendation_model\")\n",
        "\n",
        "# Declare run completed\n",
        "run.complete()\n",
        "run_id = run.id\n",
        "print (\"run id:\", run.id)\n",
        "\n",
        "predicted_ratings.printSchema()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# view current run in Azure ML\n",
        "run"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# query metrics tracked\n",
        "pprint.pprint(run.get_metrics(recursive = True))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "predicted_ratings_witherr = predicted_ratings.withColumn('err',abs(predicted_ratings[\"prediction\"] - predicted_ratings[\"count\"]))"
      ],
      "attachments": {}
    }
  ],
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}